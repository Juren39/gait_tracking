# Mikel BrostrÃ¶m ğŸ”¥ Yolo Tracking ğŸ§¾ AGPL-3.0 license

import numpy as np
import torch
from pathlib import Path
from collections import deque

from boxmot.appearance.reid_auto_backend import ReidAutoBackend
from opengait.Gait_Model import GaitModel
from boxmot.motion.cmc import get_cmc_method
from boxmot.motion.kalman_filters.xysr_kf import KalmanFilterXYSR
from boxmot.motion.kalman_filters.xywh_kf import KalmanFilterXYWH
from boxmot.utils.association import associate, linear_assignment
from boxmot.trackers.basetracker import BaseTracker
from boxmot.utils.ops import xyxy2xysr

from dataset.data_store import check_and_record, get_track_id_by_number, check_test

def k_previous_obs(observations, cur_age, k):
    if len(observations) == 0:
        return [-1, -1, -1, -1, -1]
    for i in range(k):
        dt = k - i
        if cur_age - dt in observations:
            return observations[cur_age - dt]
    max_age = max(observations.keys())
    return observations[max_age]


def convert_x_to_bbox(x, score=None):
    """
    Takes a bounding box in the centre form [x,y,s,r] and returns it in the form
      [x1,y1,x2,y2] where x1,y1 is the top left and x2,y2 is the bottom right
    """
    w = np.sqrt(x[2] * x[3])
    h = x[2] / w
    if score is None:
        return np.array([x[0] - w / 2.0, x[1] - h / 2.0, x[0] + w / 2.0, x[1] + h / 2.0]).reshape((1, 4))
    else:
        return np.array([x[0] - w / 2.0, x[1] - h / 2.0, x[0] + w / 2.0, x[1] + h / 2.0, score]).reshape((1, 5))


def speed_direction(bbox1, bbox2):
    cx1, cy1 = (bbox1[0] + bbox1[2]) / 2.0, (bbox1[1] + bbox1[3]) / 2.0
    cx2, cy2 = (bbox2[0] + bbox2[2]) / 2.0, (bbox2[1] + bbox2[3]) / 2.0
    speed = np.array([cy2 - cy1, cx2 - cx1])
    norm = np.sqrt((cy2 - cy1) ** 2 + (cx2 - cx1) ** 2) + 1e-6
    return speed / norm


class KalmanBoxTracker(object):
    """
    This class represents the internal state of individual tracked objects observed as bbox.
    """

    count = 0

    def __init__(self, det, delta_t=3, emb=None, alpha=0, max_obs=50, Q_xy_scaling = 0.01, Q_s_scaling = 0.0001):
        """
        Initialises a tracker using initial bounding box.

        """
        # define constant velocity model
        self.max_obs=max_obs
        bbox = det[0:5]
        self.conf = det[4]
        self.cls = det[5]
        self.det_ind = det[6]

        self.Q_xy_scaling = Q_xy_scaling
        self.Q_s_scaling = Q_s_scaling

        self.kf = KalmanFilterXYSR(dim_x=7, dim_z=4)
        self.kf.F = np.array(
            [
                # x  y  s  r  x' y' s'
                [1, 0, 0, 0, 1, 0, 0],
                [0, 1, 0, 0, 0, 1, 0],
                [0, 0, 1, 0, 0, 0, 1],
                [0, 0, 0, 1, 0, 0, 0],
                [0, 0, 0, 0, 1, 0, 0],
                [0, 0, 0, 0, 0, 1, 0],
                [0, 0, 0, 0, 0, 0, 1],
            ]
        )
        self.kf.H = np.array(
            [
                [1, 0, 0, 0, 0, 0, 0],
                [0, 1, 0, 0, 0, 0, 0],
                [0, 0, 1, 0, 0, 0, 0],
                [0, 0, 0, 1, 0, 0, 0],
            ]
        )
        self.kf.R[2:, 2:] *= 10.0
        self.kf.P[4:, 4:] *= 1000.0  # give high uncertainty to the unobservable initial velocities
        self.kf.P *= 10.0
        self.kf.Q[4:6, 4:6] *= self.Q_xy_scaling
        self.kf.Q[-1, -1] *= self.Q_s_scaling

        self.bbox_to_z_func = xyxy2xysr
        self.x_to_bbox_func = convert_x_to_bbox

        self.kf.x[:4] = self.bbox_to_z_func(bbox)

        self.time_since_update = 0
        self.id = KalmanBoxTracker.count
        KalmanBoxTracker.count += 1
        self.history = deque([], maxlen=self.max_obs)
        self.hits = 0
        self.hit_streak = 0
        self.age = 0
        """
        NOTE: [-1,-1,-1,-1,-1] is a compromising placeholder for non-observation status, the same for the return of
        function k_previous_obs. It is ugly and I do not like it. But to support generate observation array in a
        fast and unified way, which you would see below k_observations = np.array([k_previous_obs(...]]),
        let's bear it for now.
        """
        # Used for OCR
        self.last_observation = np.array([-1, -1, -1, -1, -1])  # placeholder
        # Used to output track after min_hits reached
        self.features = deque([], maxlen=self.max_obs)
        # Used for velocity
        self.observations = dict()
        self.velocity = None
        self.delta_t = delta_t
        self.history_observations = deque([], maxlen=self.max_obs)
        self.trajectory_buffer = deque([], maxlen=self.max_obs)  # å­˜å‚¨ 30 å¸§è½¨è¿¹
        self.gait_feature = None
        self.emb = emb

        self.frozen = False

        # self.track_id = 0  # æ•°æ®åº“åŒ¹é… ID,0å³ä¸ºå°šåœ¨è¯†åˆ«ä¸­

    def update(self, det):
        """
        Updates the state vector with observed bbox.
        """
        if det is not None:
            bbox = det[0:5]
            self.conf = det[4]
            self.cls = det[5]
            self.det_ind = det[6]
            self.frozen = False

            if self.last_observation.sum() >= 0:  # no previous observation
                previous_box = None
                for dt in range(self.delta_t, 0, -1):
                    if self.age - dt in self.observations:
                        previous_box = self.observations[self.age - dt]
                        break
                if previous_box is None:
                    previous_box = self.last_observation
                """
                  Estimate the track speed direction with observations \Delta t steps away
                """
                self.velocity = speed_direction(previous_box, bbox)
            """
              Insert new observations. This is a ugly way to maintain both self.observations
              and self.history_observations. Bear it for the moment.
            """
            self.last_observation = bbox
            self.observations[self.age] = bbox
            self.history_observations.append(bbox)

            self.time_since_update = 0
            self.hits += 1
            self.hit_streak += 1

            self.kf.update(self.bbox_to_z_func(bbox))
        else:
            self.kf.update(det)
            self.frozen = True

    def update_emb(self, emb, alpha=0.9):
        self.emb = alpha * self.emb + (1 - alpha) * emb
        self.emb /= np.linalg.norm(self.emb)

    def get_emb(self):
        return self.emb

    def apply_affine_correction(self, affine):
        m = affine[:, :2]
        t = affine[:, 2].reshape(2, 1)
        # For OCR
        if self.last_observation.sum() > 0:
            ps = self.last_observation[:4].reshape(2, 2).T
            ps = m @ ps + t
            self.last_observation[:4] = ps.T.reshape(-1)

        # Apply to each box in the range of velocity computation
        for dt in range(self.delta_t, -1, -1):
            if self.age - dt in self.observations:
                ps = self.observations[self.age - dt][:4].reshape(2, 2).T
                ps = m @ ps + t
                self.observations[self.age - dt][:4] = ps.T.reshape(-1)

        # Also need to change kf state, but might be frozen
        self.kf.apply_affine_correction(m, t)

    def predict(self):
        """
        Advances the state vector and returns the predicted bounding box estimate.
        """
        # Don't allow negative bounding boxes
        if (self.kf.x[6] + self.kf.x[2]) <= 0:
            self.kf.x[6] *= 0.0
        Q = None

        self.kf.predict(Q=Q)
        self.age += 1
        if self.time_since_update > 0:
            self.hit_streak = 0
        self.time_since_update += 1
        self.history.append(self.x_to_bbox_func(self.kf.x))
        return self.history[-1]

    def get_state(self):
        """
        Returns the current bounding box estimate.
        """
        return self.x_to_bbox_func(self.kf.x)

    def mahalanobis(self, bbox):
        """Should be run after a predict() call for accuracy."""
        return self.kf.md_for_measurement(self.bbox_to_z_func(bbox))
    
    def is_ready_for_embedding(self):
        """
        åªæœ‰å½“è½¨è¿¹æ»¡ 30 å¸§æ—¶ï¼Œæ‰èƒ½è®¡ç®—ç‰¹å¾
        """
        return len(self.trajectory_buffer) == 30
    
    def update_trajectory(self, img, det):
        """
        æ›´æ–°å†å²æ­¥æ€è½¨è¿¹ï¼Œå…·ä½“å­˜å‚¨å½¢å¼ä¸ºæ£€æµ‹æ¡†å›¾ç‰‡ã€‚
        """
        bbox = det[0:4]
        h, w = img.shape[:2]
        x1, y1, x2, y2 = bbox.astype('int')
        x1, y1, x2, y2 = max(0, x1), max(0, y1), min(w - 1, x2), min(h - 1, y2)
        self.trajectory_buffer.append(img[y1:y2, x1:x2])

    def should_match_db(self):
        """
        æ”’å¤Ÿè¶³å¤Ÿé•¿çš„é•¿åº¦ï¼Œéœ€è¦æ¨è¿›å»å¾—åˆ°è½¨è¿¹çš„æ­¥æ€ç‰¹å¾
        """
        return len(self.trajectory_buffer) >= 50
class DeepOcSort(BaseTracker):
    """
    DeepOCSort Tracker: A tracking algorithm that utilizes a combination of appearance and motion-based tracking.

    Args:
        model_weights (str): Path to the model weights for ReID (Re-Identification).
        device (str): Device on which to run the model (e.g., 'cpu' or 'cuda').
        fp16 (bool): Whether to use half-precision (fp16) for faster inference on compatible devices.
        per_class (bool, optional): Whether to perform per-class tracking. If True, tracks are maintained separately for each object class.
        det_thresh (float, optional): Detection confidence threshold. Detections below this threshold will be ignored.
        max_age (int, optional): Maximum number of frames to keep a track alive without any detections.
        min_hits (int, optional): Minimum number of hits required to confirm a track.
        iou_threshold (float, optional): Intersection over Union (IoU) threshold for data association.
        delta_t (int, optional): Time delta for velocity estimation in Kalman Filter.
        asso_func (str, optional): Association function to use for data association. Options include "iou" for IoU-based association.
        inertia (float, optional): Weight for inertia in motion modeling. Higher values make tracks less responsive to changes.
        w_association_emb (float, optional): Weight for the embedding-based association score.
        alpha_fixed_emb (float, optional): Fixed alpha for updating embeddings. Controls the contribution of new and old embeddings in the ReID model.
        aw_param (float, optional): Parameter for adaptive weighting between association costs.
        embedding_off (bool, optional): Whether to turn off the embedding-based association.
        cmc_off (bool, optional): Whether to turn off camera motion compensation (CMC).
        aw_off (bool, optional): Whether to turn off adaptive weighting.
        Q_xy_scaling (float, optional): Scaling factor for the process noise covariance in the Kalman Filter for position coordinates.
        Q_s_scaling (float, optional): Scaling factor for the process noise covariance in the Kalman Filter for scale coordinates.
        **kwargs: Additional arguments for future extensions or parameters.
    """
    def __init__(
        self,
        reid_weights: Path,
        gait_weights: Path,
        device: torch.device,
        half: bool,
        save_file: dict,
        mode: str,
        per_class: bool = False,
        det_thresh: float = 0.3,
        max_age: int = 30,
        min_hits: int = 3,
        iou_threshold: float = 0.3,
        delta_t: int = 3,
        asso_func: str = "iou",
        inertia: float = 0.2,
        w_association_emb: float = 0.5,
        alpha_fixed_emb: float = 0.95,
        aw_param: float = 0.5,  
        embedding_off: bool = False,
        cmc_off: bool = False,
        aw_off: bool = False,
        Q_xy_scaling: float = 0.01,
        Q_s_scaling: float = 0.0001,
        **kwargs: dict
    ):
        super().__init__(max_age=max_age, per_class=per_class, asso_func=asso_func)
        """
        Sets key parameters for SORT
        """
        self.save_file = save_file
        self.mode = mode
        self.max_age = max_age
        self.min_hits = min_hits
        self.iou_threshold = iou_threshold
        self.det_thresh = det_thresh
        self.delta_t = delta_t
        self.asso_func = asso_func
        self.inertia = inertia
        self.w_association_emb = w_association_emb
        self.alpha_fixed_emb = alpha_fixed_emb
        self.aw_param = aw_param
        self.per_class = per_class
        self.Q_xy_scaling = Q_xy_scaling
        self.Q_s_scaling = Q_s_scaling
        KalmanBoxTracker.count = 1

        self.model = ReidAutoBackend(
            weights=reid_weights, device=device, half=half
        ).model
        self.gait_model = GaitModel(
            cfgs_path=gait_weights
        )
        # "similarity transforms using feature point extraction, optical flow, and RANSAC"
        self.cmc = get_cmc_method('sof')()
        self.embedding_off = embedding_off
        self.cmc_off = cmc_off
        self.aw_off = aw_off

    @BaseTracker.on_first_frame_setup
    @BaseTracker.per_class_decorator
    def update(self, dets: np.ndarray, img: np.ndarray, embs: np.ndarray = None) -> np.ndarray:
        """
        Params:
          dets - a numpy array of detections in the format [[x1,y1,x2,y2,score,cls],[x1,y1,x2,y2,score,cls],...]
        Requires: this method must be called once for each frame even with empty detections
        (use np.empty((0, 5)) for frames without detections).
        Returns the a similar array, where the last column is the object ID.
        NOTE: The number of objects returned may differ from the number of detections provided.
        """
        # dets, s, c = dets.data
        # print(dets, s, c)
        self.check_inputs(dets, img)

        self.frame_count += 1
        self.height, self.width = img.shape[:2]
        # å¯¹æ£€æµ‹æ¡† dets è¿›è¡Œé¢„å¤„ç†ï¼Œç­›é€‰å‡ºç½®ä¿¡åº¦å¤§äº det_threshï¼ˆé»˜è®¤ 0.3ï¼‰çš„ç›®æ ‡ã€‚
        scores = dets[:, 4]
        dets = np.hstack([dets, np.arange(len(dets)).reshape(-1, 1)]) # ç»™ dets è¿½åŠ ç´¢å¼•ç¼–å·ï¼Œä¾¿äºè·Ÿè¸ªæ•°æ®å…³è”
        assert dets.shape[1] == 7
        remain_inds = scores > self.det_thresh
        dets = dets[remain_inds]
        # dets -> [x1, y1, x2, y2, score, class_id, det_index]

        # appearance descriptor extraction
        if self.embedding_off or dets.shape[0] == 0:
            dets_embs = np.ones((dets.shape[0], 1))
        elif embs is not None:
            dets_embs = embs
        else:
            # (Ndets x X) [512, 1024, 2048]

            ##############################
            # å®éªŒ1: re-idç‰¹å¾å…¨éƒ¨æ¢æˆgaitç‰¹å¾çš„å½±å“
            # embedding_list = []
            # for det in dets:
            #     x1, y1, x2, y2 = det[:4].astype(int)
            #     h, w = img.shape[:2]
            #     x1, y1, x2, y2 = max(0, x1), max(0, y1), min(w - 1, x2), min(h - 1, y2)
            #     crop_img = img[y1:y2, x1:x2]
            #     embedding = self.gait_model.extract_gait_feature([crop_img])
            #     # 3) æ”¶é›†åˆ°åˆ—è¡¨ä¸­
            #     embedding_list.append(embedding)
            # # 4) æŠŠåˆ—è¡¨æ‹¼æˆ (N, emb_dim) çš„äºŒç»´ç»“æ„ (numpy æˆ– torch)
            #    æ¯”å¦‚è‹¥ embedding æ˜¯ numpy å‘é‡ï¼Œç›´æ¥ np.stack
            # dets_embs = np.stack(embedding_list, axis=0)
            dets_embs = self.model.get_features(dets[:, 0:4], img) # Re-idå¤–è§‚ç‰¹å¾æå– -> dets_embs
        # CMCå¤„ç†ï¼Œå…¨å±€è¿åŠ¨è¡¥å¿ï¼Œæ¶ˆé™¤æ‘„åƒæœºè¿åŠ¨å¯¹ç›®æ ‡è·Ÿè¸ªçš„å½±å“ã€‚
        if not self.cmc_off:
            transform = self.cmc.apply(img, dets[:, :4])
            for trk in self.active_tracks:
                trk.apply_affine_correction(transform)

        trust = (dets[:, 4] - self.det_thresh) / (1 - self.det_thresh) #è®¡ç®—å¹¶å½’ä¸€åŒ–trust
        af = self.alpha_fixed_emb
        # self.alpha_fixed_emb æ˜¯ å›ºå®šçš„ alpha å€¼ï¼Œç”¨äº ç‰¹å¾æ›´æ–°çš„å¹³æ»‘æƒé‡ï¼Œç±»ä¼¼äº æŒ‡æ•°å¹³æ»‘ã€‚
        # å€¼è¶Šå¤§ï¼Œè¡¨ç¤º æ–°ç‰¹å¾å¯¹æ—§ç‰¹å¾çš„å½±å“è¾ƒå°ï¼Œå¹³æ»‘æ›´æ–°ã€‚å€¼è¶Šå°ï¼Œè¡¨ç¤º æ–°ç‰¹å¾æ›´æ–°å¾—æ›´å¿«ï¼Œé€‚åº”æ€§æ›´å¼ºã€‚

        # From [self.alpha_fixed_emb, 1], goes to 1 as detector is less confident
        dets_alpha = af + (1 - af) * (1 - trust)
        # è®¡ç®— dets_alphaï¼Œç”¨äºæ›´æ–° ReID ç‰¹å¾
        # trust è¶Šé«˜ï¼Œè¯´æ˜æ£€æµ‹å™¨ç½®ä¿¡åº¦è¶Šé«˜ï¼Œ1 - trust å°±è¶Šå°ï¼Œæœ€ç»ˆ dets_alpha è¶Šæ¥è¿‘ self.alpha_fixed_embï¼Œè¡¨ç¤º ä¿ç•™æ›´å¤šæ—§ç‰¹å¾ã€‚
        # trust è¶Šä½ï¼Œè¯´æ˜æ£€æµ‹å™¨ç½®ä¿¡åº¦è¾ƒä½ï¼Œ1 - trust è¶Šå¤§ï¼Œæœ€ç»ˆ dets_alpha è¶‹å‘ 1ï¼Œè¡¨ç¤º æ›´å¿«æ›´æ–°æ–°ç‰¹å¾ã€‚

        # get predicted locations from existing trackers.
        # é¢„æµ‹å½“å‰æ´»è·ƒè½¨è¿¹ self.active_tracks çš„ä¸‹ä¸€æ—¶åˆ»ä½ç½®ï¼Œå¹¶è·å–å…¶å¤–è§‚ç‰¹å¾ trk_embs
        trks = np.zeros((len(self.active_tracks), 5))
        trk_embs = []
        to_del = []
        ret = []
        for t, trk in enumerate(trks):
            pos = self.active_tracks[t].predict()[0] # é€šè¿‡ å¡å°”æ›¼æ»¤æ³¢å™¨ é¢„æµ‹ä¸‹ä¸€æ—¶åˆ»çš„ç›®æ ‡ä½ç½®
            trk[:] = [pos[0], pos[1], pos[2], pos[3], 0]
            if np.any(np.isnan(pos)): # å¦‚æœ pos åŒ…å« NaN å€¼ï¼ˆå¯èƒ½æ˜¯ç”±äºé¢„æµ‹å¤±è´¥æˆ–åˆå§‹åŒ–é—®é¢˜ï¼‰
                to_del.append(t)
            else:
                trk_embs.append(self.active_tracks[t].get_emb())
        trks = np.ma.compress_rows(np.ma.masked_invalid(trks)) 

        if len(trk_embs) > 0: # trk_embs å­˜å‚¨çš„æ˜¯ æ‰€æœ‰æ´»è·ƒè½¨è¿¹çš„ ReID ç‰¹å¾å‘é‡ï¼Œç”¨äºç›®æ ‡å…³è”åŒ¹é…ã€‚
            trk_embs = np.vstack(trk_embs)
        else:
            trk_embs = np.array(trk_embs)

        for t in reversed(to_del):
            self.active_tracks.pop(t) # æ¸…ç†æ— æ•ˆè½¨è¿¹
        
        #è®¡ç®—è¿åŠ¨ä¿¡æ¯ï¼Œ æœ€åä¸€æ¬¡è§‚æµ‹çš„è¾¹ç•Œæ¡†ï¼Œ å†å²è§‚æµ‹ç‚¹
        velocities = np.array([trk.velocity if trk.velocity is not None else np.array((0, 0)) for trk in self.active_tracks])
        last_boxes = np.array([trk.last_observation for trk in self.active_tracks])
        k_observations = np.array([k_previous_obs(trk.observations, trk.age, self.delta_t) for trk in self.active_tracks])

        """
            First round of association
        """
        ####################################
        #       compute stage1_emb_cost
        ####################################
        # (M detections X N tracks, final score
        if self.embedding_off or dets.shape[0] == 0 or trk_embs.shape[0] == 0:
            stage1_emb_cost = None
        else:
            stage1_emb_cost = dets_embs @ trk_embs.T
        matched, unmatched_dets, unmatched_trks = associate(
            dets[:, 0:5],
            trks,
            self.asso_func,
            self.iou_threshold,
            velocities,
            k_observations,
            self.inertia,
            img.shape[1], # w
            img.shape[0], # h
            stage1_emb_cost,
            self.w_association_emb,
            self.aw_off,
            self.aw_param,
        )
        for m in matched:
            self.active_tracks[m[1]].update(dets[m[0], :])
            self.active_tracks[m[1]].update_emb(dets_embs[m[0]], alpha=dets_alpha[m[0]])
            self.active_tracks[m[1]].update_trajectory(img, dets[m[0], :])

        """
            Second round of associaton by OCR
        """
        if unmatched_dets.shape[0] > 0 and unmatched_trks.shape[0] > 0:
            left_dets = dets[unmatched_dets]
            left_dets_embs = dets_embs[unmatched_dets]
            left_trks = last_boxes[unmatched_trks]
            left_trks_embs = trk_embs[unmatched_trks]

            iou_left = self.asso_func(left_dets, left_trks)
            # TODO: is better without this
            emb_cost_left = left_dets_embs @ left_trks_embs.T
            if self.embedding_off:
                emb_cost_left = np.zeros_like(emb_cost_left)
            iou_left = np.array(iou_left)
            if iou_left.max() > self.iou_threshold:
                """
                NOTE: by using a lower threshold, e.g., self.iou_threshold - 0.1, you may
                get a higher performance especially on MOT17/MOT20 datasets. But we keep it
                uniform here for simplicity
                """
                rematched_indices = linear_assignment(-iou_left)
                to_remove_det_indices = []
                to_remove_trk_indices = []
                for m in rematched_indices:
                    det_ind, trk_ind = unmatched_dets[m[0]], unmatched_trks[m[1]]
                    if iou_left[m[0], m[1]] < self.iou_threshold:
                        continue
                    self.active_tracks[trk_ind].update(dets[det_ind, :])
                    self.active_tracks[trk_ind].update_emb(dets_embs[det_ind], alpha=dets_alpha[det_ind])
                    self.active_tracks[m[1]].update_trajectory(img, dets[det_ind, :])
                    to_remove_det_indices.append(det_ind)
                    to_remove_trk_indices.append(trk_ind)
                unmatched_dets = np.setdiff1d(unmatched_dets, np.array(to_remove_det_indices))
                unmatched_trks = np.setdiff1d(unmatched_trks, np.array(to_remove_trk_indices))

        for m in unmatched_trks:
            self.active_tracks[m].update(None)

        # create and initialise new trackers for unmatched detections
        for i in unmatched_dets:
            trk = KalmanBoxTracker(
                dets[i],
                delta_t=self.delta_t,
                emb=dets_embs[i],
                alpha=dets_alpha[i],
                Q_xy_scaling=self.Q_xy_scaling, 
                Q_s_scaling=self.Q_s_scaling,                
                max_obs=self.max_obs
            )
            trk.update_trajectory(img, dets[i, :])
            self.active_tracks.append(trk)
            matched_id = check_and_record(trk.emb, None, self.mode, self.save_file, threshold=0.65)
            trk.id = matched_id
        i = len(self.active_tracks)
        
        # # ç”¨æ•°æ®åº“è¿”å›çš„ ID èµ‹å€¼ç»™ trk_id
        # if self.mode != 'annotation':
        #     reid_feature = dets_embs[i]
        #     if self.mode == 'registration':
        #         matched_id = check_and_record(reid_feature, self.mode, self.save_file, box_id[i], threshold=0.65)
        #     else:
        #         matched_id = check_and_record(reid_feature, self.mode, self.save_file, threshold=0.65)
        #     trk.id = matched_id
        # for trk in self.active_tracks:
        #     if trk.should_match_db():
        #         trk.db_id = check_and_record(trk.trajectory_buffer, self.mode, self.save_file, threshold=0.65)
        #     if trk.is_ready_for_embedding():
        #         trk.emb = self.model.get_features(np.array(trk.trajectory_buffer), img)

        for trk in reversed(self.active_tracks):
            if trk.last_observation.sum() < 0:
                d = trk.get_state()[0]
            else:
                """
                this is optional to use the recent observation or the kalman filter prediction,
                we didn't notice significant difference here
                """
                d = trk.last_observation[:4]
            if (trk.time_since_update < 1) and (trk.hit_streak >= self.min_hits or self.frame_count <= self.min_hits):
                # +1 as MOT benchmark requires positive
                ret.append(np.concatenate((d, [trk.id], [trk.conf], [trk.cls], [trk.det_ind] )).reshape(1, -1))
            i -= 1
            # remove dead tracklet
            if trk.time_since_update > self.max_age:
                self.active_tracks.pop(i)
        if len(ret) > 0:
            return np.concatenate(ret)
        return np.array([])
    
    def registration(self, dets: list, imgs: list = None) -> list: #mainæ–¹æ³•ä¸­çš„load_json_bboxeså¯¹åº”çš„track_idä»¥åŠidé—®é¢˜ï¼Œéœ€è¦ä¿®å¤annotationæ¨¡å¼æ ‡æ³¨å‡ºæ¥çš„æ–‡æœ¬ã€‚
        """
        å¯¹å¤šå¸§å›¾åƒè¿›è¡Œæ³¨å†Œ: 
        1. æŒ‰å¸§éå†ï¼Œè¯»å–å…¶ä¸­æ‰€æœ‰æ£€æµ‹æ¡† (x1,y1,x2,y2,cls,id)ã€‚
        2. è£å‰ªå‡ºå¯¹åº”åŒºåŸŸå¹¶æå– Re-ID ç‰¹å¾ (å¯åŠ æ­¥æ€ç‰¹å¾)ã€‚
        3. è°ƒç”¨ check_and_record å°†ç‰¹å¾æ³¨å†Œè¿›æ•°æ®åº“ã€‚

        Args:
            imgs (List[np.ndarray] | np.ndarray):
                å¤šå¸§å›¾åƒåºåˆ—ï¼Œå¯æ˜¯ Python åˆ—è¡¨[frame0, frame1, ...],
                æˆ–å½¢çŠ¶ (T, H, W, C) çš„ 4D NumPy æ•°ç»„ã€‚
            dets (List[np.ndarray] | np.ndarray):
                æ£€æµ‹æ¡†åˆ—è¡¨æˆ–æ•°ç»„ï¼Œé•¿åº¦/ç¬¬ä¸€ç»´ä¸ imgs å¯¹åº”ã€‚
                æ¯å¸§æ˜¯ä¸€ä¸ª (M, 4/5/...) çš„æ•°ç»„, å…¶ä¸­å‰4åˆ—æ˜¯ [x1, y1, x2, y2]ã€‚
            box_ids (List[List[int]] | np.ndarray | None, optional):
                ä¸ dets å¯¹åº”çš„ç›®æ ‡ ID, å½¢çŠ¶ (T, M)ã€‚
                è‹¥ None, åˆ™é»˜è®¤ç”¨ (frame_idx, detection_idx) ä½œä¸ºæ ‡è¯†ã€‚

        Returns:
            dict:
                é”®: å¯æ ¹æ®éœ€è¦ä½¿ç”¨ (frame_idx, detection_idx) æˆ–è€… box_ids[frame_idx][det_idx]ã€‚
                å€¼: matched_id (æ•°æ®åº“ä¸­çš„ ID)ã€‚
        """
        if len(dets) == 0:
            return

        assert len(imgs) == len(dets), "imgs å’Œ dets çš„å¸§æ•°ä¸åŒ¹é…"
        results = {}
        for f_idx, (frame, frame_dets) in enumerate(zip(imgs, dets)):
            if frame_dets is None or len(frame_dets) == 0:
                continue
            h, w = frame.shape[:2]
            unmatched_dets = []
            dets_embs = self.model.get_features(frame_dets[:, 0:4], frame)
            trust = (frame_dets[:, 4] - self.det_thresh) / (1 - self.det_thresh) #è®¡ç®—å¹¶å½’ä¸€åŒ–trust
            af = self.alpha_fixed_emb
            dets_alpha = af + (1 - af) * (1 - trust)
            
            # è£å‰ªå¹¶è®°å½•ID
            for i, det in enumerate(frame_dets):
                x1, y1, x2, y2, score = det[:5].astype(int) # [x1, y1, x2, y2, confidence, cls, det_id]
                det_id = str(get_track_id_by_number(Path('./dataset/id_name_mapping.txt'), det[6]))
                match = False

                for trk in self.active_tracks:
                    if det_id == trk.track_id:
                        trk.update(frame_dets[i, :])
                        trk.update_emb(dets_embs[i], alpha=dets_alpha[i])
                        trk.update_trajectory(frame, frame_dets[i, :])
                        match = True
                        break
                if not match:
                    trk = KalmanBoxTracker(
                        frame_dets[i],
                        delta_t=self.delta_t,
                        emb=dets_embs[i],
                        alpha=dets_alpha[i],
                        Q_xy_scaling=self.Q_xy_scaling, 
                        Q_s_scaling=self.Q_s_scaling,                
                        max_obs=self.max_obs,
                    )
                    trk.track_id = det_id
                    trk.trajectory_buffer = deque([], maxlen=len(dets))
                    trk.update_trajectory(frame, frame_dets[i, :])
                    self.active_tracks.append(trk)
        box_id_list = []
        for trk in self.active_tracks:
            trk.gait_feature = self.gait_model.extract_gait_feature(trk.trajectory_buffer)
            matched_id = check_and_record(trk.emb, trk.gait_feature, self.mode, self.save_file, trk.track_id, threshold=0.65) 
            box_id_list.append(trk.track_id)
        return box_id_list


